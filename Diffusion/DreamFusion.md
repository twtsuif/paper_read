# DreamFusion



## 简介

基于概率密度蒸馏的损失，使用2D扩散模型作为参数图像生成器优化的先验

类似DeepDream，梯度下降优化随机初始化的3D模型，随机角度进行2D渲染



github.io结果展示：https://dreamfusion3d.github.io/

高真实性外观、深度图、normals

组合对象到同一场景

训练的NeRF可以通过移动立方体算法导出3D渲染器和模型软件

渲染的3D模型从两个视图呈现，textureless renders和 normals to the right



提出Score Distillation Sampling(SDS)，通过优化损失函数

允许我们在任意参数空间(如3D空间)中优化，只要能微分地映射回图像即可，我们使用NeRF来定义这种可微映射

单独的SDS可以产生合理的场景外观，DreamFusion添加了额外的正则化器和优化策略，来改进

训练后的NeRF是连贯的，可使用朗伯着色模型重新照明



3D资产是在Blender和Maya3D等建模软件手工设计的，需要大量时间和专业知识



GAN通过在输出的3D场景的2D图像渲染上，放置对抗性损失，从单个对象类别的照片中，学习可控3D生成器，尚未证明它们支持任意文本



NeRF神经逆向渲染的关键工具

很多3D生成已经成功将类似NeRF的模型作为构建块，纳入更大的生成系统

Dream Fields使用 CLIP 的冻结图像-文本联合嵌入模型和基于优化的方法来训练 NeRF

我们与DreamField类似，但使用源自 2D 扩散模型蒸馏的损失替换 CLIP

最小化，具有基于扩散前向过程和预训练扩散模型学习的得分函数的共享均值的，高斯分布family之间的 KL 散度

SDS方法可以通过可微分图像参数化的优化，进行采样

SDS与3D生成任务定制的NeRF变体结合



## Method

前向过程，给定初始数据点x，积分中间时间步， 计算时间步t的潜在变量的边缘分布q(zt|x) = N (αtx, σ2 t I).

积分数据密度qx的边缘为q(zt) = ∫ q(zt|x)q(x) dx，对应数据分布的平滑版本

选择系数α和σ，使得qzt接近开始过程的数据密度σ0≈0，前向结束时接近高斯分布σT≈1，αt的平方=1-σt的平方来保留方差



生成模型p缓慢添加结构，理论上，只要足够的时间步，最佳逆向处理步骤也是高斯分布，并且与最佳MSE降噪器相关