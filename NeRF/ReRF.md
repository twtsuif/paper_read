# ReRF

Neural Residual Radiance Fields for Streamably Free-Viewpoint Videos

神经残差辐射场，可以流式传输自由视点视频



利用残差辐射场和全局MLP，实现可压缩和可流式传输的辐射场建模

我们基于ReRF的编解码方案和流播放器，提供丰富交互体验



## 架构图

<img src="https://cdn.jsdelivr.net/gh/twtsuif/picture/twtsuif2023-08-28/a0e145e9ed88b5e2b6088aabd5b47ec1--d01d--image-20230828185500407.png" alt="image-20230828185500407" style="zoom:80%;" />

顺序训练方案，为每个帧生成带有Mi和ri的紧凑表示

基于编解码器和播放器进行压缩



## 摘要

当前利用神经渲染来推动FVV仅限于离线渲染或最小运动的简洁序列

ReRF采用高度紧凑的神经表示，支持长时间动态场景，实时FVV渲染

显式建模**时空特征空间**，**相邻时间戳的残差信息**，**基于全局坐标的微小MLP**作为特征解码器

具体地，使用**紧凑的运动网格**和**残差特征网格**，利用**帧间特征相似性**

不牺牲质量的情况下，处理大型运动

进一步提出**顺序训练方案**，维持运动网格和残差网格的**平滑性和稀疏性**

基于ReRF，设计了特殊的FVV编解码器，三个数量级的压缩率，提供配套的ReRF播放器



## 简介

FVV的挑战：从数据处理和压缩，到流式传输和渲染

基于几何的方法，重建动态3D网格或点云。基于图像的方法，在密集传输的镜头上插值新视图。

都依赖高质量重建，易受遮挡和无纹理区域的影响

各种方法都集中在，使用更好的表示来'sculpt'特征空间，最近的研究包括：显式特征量、多尺度hash、codebook、三平面、张量。都是为了静态场景



全局MLP将**时空连续特征空间**中的特征，解码为**radiance outputs**

简单的逐帧方法：一系列**独立的空间特征**空间上使用静态方法。丢弃了时间一致性。

最近的方法：通过将每帧warp进**规范空间**，维持规范空间特征，来重现每个实时帧的特征

​	很多弥补时间运动的方案：使用隐式匹配，数据驱动先验如深度、傅里叶特征、光流、面部运动先验

​	然而全局规范空间的严重依赖容易受到大型运动或拓扑改变的影响

最近的工作开始探索相邻帧的特征冗余，但无法维持连贯的时空特征空间



为了保持训练和推理的高效，使用显式网格表示，对特征空间建模

然而，只对第一个关键帧训练来获得整个序列的MLP解码器，同时使用得到的网格体作为初始特征体

每个后续帧，使用紧凑的运动网格Mt和残差特征网格rt

- 低分辨率运动网格：从当前帧到前一帧的位置偏移
- 稀疏残差网格：补偿误差和新观察到的区域

充分利用相邻帧相似性，获取当前帧的完整特征网格，避免使用全局规范空间

运动网格和残差网格都可压缩



两阶段方案

引入了新的**运动池策略**保持帧间运动网格的平滑性和紧凑型，引入了稀疏正则化器提高ReRF的紧凑性

设计的ReRF编解码器，遵循传统的基于关键帧策略



## 相关工作

### 静态场景的NVS

光场通过两平面参数化

早期方法通过插值，可以实时渲染但要缓存所有光线

基于mesh的表示可以高效存储且记录纹理，但不好适应复杂的拓扑

多平面图像无拓扑性质可以处理复杂场景



### 动态场景的NVS

光照变化和物体移动

一种方法：重建动态场景并从新视图渲染几何，RGB和RGB-D

一种方法：神经网络将每个图像与其他图像回归，实现视图、时间、光线插值

一种方法：编解码器架构，将2D转为3D体积，体渲染端到端训练

一种方法：将点特征与多视图图像结合，进行动态人体渲染

一种方法：使用运动流特征向量进行静态图像动画



扩展NeRF

- 直接在时间上调节辐射场
- 在每个时间戳，学习空间偏移，从当前场景，到一个学习的规范辐射场
- 在额外的高维坐标上设置NeRF条件，解决连续变形场之外的不连续拓扑变化
- 对场景每个点的轨迹建模
- 使用显式体素对动态场景的规范空间和变形场进行建模
- 通过傅里叶系数对时变密度和颜色进行建模，以将基于八叉树的辐射场扩展到动态场景



### NeRF加速和压缩

浅MLP解码器将NeRF分解为显式3D特征编码，减少复杂的MLP计算

但是与这些3D结构相关的额外存储是个问题

最近的方法，在视频序列的稀疏体素网格上采用窄带调谐，每帧仍然MB

NerfPlayer将4D空间分解为静态、变形和新区域，但受到视频序列长度的限制



## 神经残差辐射场

### 运动感知残差场

ReRF中，使用显式网格表示，显式密度网格 Vσ 和颜色特征网格 Vc

![image-20230828183420127](https://cdn.jsdelivr.net/gh/twtsuif/picture/twtsuif2023-08-28/869a0818bd374a1f38ae9b2d813b4936--9199--image-20230828183420127.png)

interp表示网格上的三线性插值函数，Φ是用于加速的浅MLP

向Vc中附加额外通道，合并两个网格为一个公共特征网格f



为了进一步表示动态，基于坐标的小MLP作为时空特征空间的**全局特征解码器**

使用每帧特征网格f，但丢弃了时间一致性

DeVRF维护一个具有密集运动场Dt的规范特征网络f1，由于对规范空间的依赖，无法适应大型运动或拓扑变化

首先将Mt应用于ft-1提取帧间冗余  ![image-20230828190742286](https://cdn.jsdelivr.net/gh/twtsuif/picture/twtsuif2023-08-28/7f94e426fd2bb46884a5da2f89ba9b15--08b7--image-20230828190742286.png)

然后通过残差补偿来恢复整个网络

与显式网格ft相比，我们的运动感知残差表示是紧凑且友好的，建模相关时空特征空间中的特征变化



### 顺序残差场生成

根据现有方法，获取第一帧



#### 运动网格评估

follow DeVRF到密集运动场Dt

体素pt中的运动向量可以指向前一帧中不同体素pt-1

与标准池化操作类似，使用均值向量指向的体素 $\overline{p}_{t-1}$ 

将Dt分割成立方体 8\*8\*8，应用平均池化，强制每个立方体共享相同的运动向量，下采样低分辨率运动网格Mt，比原始密集网格小512倍

跟踪前一帧的特征立方体，进一步降低残留体素的熵



#### 残差网格优化

粗略补偿帧间运动引起的特征差异，优化期间固定$\hat{f}_t$和Φ，并将梯度反向传播到残差网格来更新

除了光度损失，还通过使用L1损失进行正则化，增强稀疏性，提高紧凑性

这种稀疏公式还强制 rt 仅补偿帧间残差或新观察到的区域的稀疏信息

![image-20230828193845860](https://cdn.jsdelivr.net/gh/twtsuif/picture/twtsuif2023-08-28/da4a16d8b86be82620094a0b1141d416--d2a6--image-20230828193845860.png)



## ReRF编解码器和可流式应用

### 特征级残差压缩

编解码器流程图：

![image-20230828194417684](https://cdn.jsdelivr.net/gh/twtsuif/picture/twtsuif2023-08-28/bb243412f559a326511401bb3605d0b5--3cd2--image-20230828194417684.png)

我们首先将特征网格序列划分为几个连续的特征网格组gof

![image-20230828194554589](https://cdn.jsdelivr.net/gh/twtsuif/picture/twtsuif2023-08-28/a86ac70b0d4e5f7067f40e97f7163d2d--1ad8--image-20230828194554589.png)



视频压缩相关...