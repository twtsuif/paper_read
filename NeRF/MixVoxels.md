# MixVoxels

Mixed Neural Voxels for Fast Multi-view Video Synthesis

用于多视图视频快速合成的混合神经体素





![image-20230622142211603](https://cdn.jsdelivr.net/gh/twtsuif/picture/twtsuif2023-06-22/2594bb695e608822f6313b94b1aba4a3--7b59--image-20230622142211603.png)

快速重建4D动态场景，并在空间和时间上合成新视图，15分钟300帧场景训练，我们对渲染的新视图视频进行可视化，我们还可视化了学到的场景几何



## Abstract

现实环境的复杂性和高度动态的运动，从现实世界的多视图输入中，合成高真实的视频非常有挑战

NeRF训练时间太久

提出的混合体素将4D动态场景表示为静态体素和动态体素的混合体素，使用不同网络处理

静态体素所需模态的计算可以通过轻量级模型来处理，根本上减少计算量，特别是对于许多由静态背景主导的日常动态场景

分离这两类体素，我们提出了一个新的变化场来估计每个体素的时间变化

动态体素，我们设计了一种内积时间查询方法来高效地查询多个时间步长，这是必要的恢复高动态的运动

结果表明PSNR更好



## Introduction

从多视图视频中动态场景重建是一个重要而具有挑战的问题，许多潜在应用场景(电影的交互式自由视图控制、定格子弹时间等效果、各种潜在VR/AR应用)

许多方法通过额外的时间查询或显式变形场将NeRF扩展到动态场景，很多都是针对单眼输入视频在相对简单的动态场景下的设置

更复杂的动态场景：使用多视图同步视频来提供密集的时空监督



Li等人提出了一个真实世界的动态场景数据集，包括许多挑战性，如高机率的对象、拓扑变化和体积效应，它们通过分层训练方案和射线重要性采样策略来解决。仍然存在一些挑战：（1）训练和渲染需要大量的时间和计算资源。（2）具有复杂运动的高度动态场景仍然难以跟踪。



我们针对多视图3D视频合成，设计了MixVoxels来解决上述问题

基于显式的体素网格，静态场景中训练和渲染很快

一旦动态场景由一些静态空间组成，训练速度将受益于混合体素

对于物理世界中发生的各种事件，环境中的静态成分大多数占主导地位，混合体素显著加快训练

体素的分离使得时变模型聚焦于动态区域，避免了时间感知体素受静态空间的影响而产生模糊运动

通过经验验证：使模型在高度动态的区域中学习到了清晰的边界

将我们的方法从复杂的重要性采样策略中解放

3090GPU



贡献：

- 设计了简单有效的动态体素网格表示，内积时间查询方法来高效地查询多个时间步长，提高高度动态对象的渲染质量
- 设计了有效的变化场来分离静态和动态空间，提出混合体素来加速训练和渲染
- 进行了定性和定量的实验，与隐式动态场景表示相比，所提出的混合体素以5000倍的训练速度获得了具有更好的渲染质量



## Related Works

### 静态场景的新视图合成

不同的方法用不同的表示，来表示底层几何

基于网格的方法，具有紧凑且易于渲染的表面的场景，而优化网格以适应复杂的场景是具有挑战性的。

基于体积的方法，例如体素网格和多平面图像（MPIs）更适合对复杂和半透明的场景进行建模，例如光滑流畅。

神经辐射场



### 动态场景的新视图合成

最近提出了许多针对非刚性动态场景的 NeRF 扩展，它们以单目视频作为输入来学习deformation和辐射场

这些方法可分为显式和隐式地建模deformation

隐式：联合学习非解耦deformation和外观

显式：学习分离的deformation和辐射场，以及deformation场通常采用与规范静态空间相对运动的形式

仅使用单目视频重建复杂的一般场景仍然很困难，大多数方法仅限于固定场景，例如人体模型或受限运动。

对于现实世界的复杂场景，由于对每个视点和时刻的密集监督，从同步多视图视频重建更有前景。

Neural Volumes建议使用体积表示。他们采用编码器-解码器网络将输入图像转换为 3D 体积，并通过可微的光线行进操作解码潜在表示。
