# SNeRG

Baking Neural Radiance Fields for Real-Time View Synthesis

Baking NeRF来进行实时视图合成



## 架构图

![image-20230829215730294](https://cdn.jsdelivr.net/gh/twtsuif/picture/twtsuif2023-08-29/de1e44b9797115ce1dc288348af0501b--39bf--image-20230829215730294.png)

联合设计延迟NeRF和一个程序，来在稀疏3D体素网格中，预计算和存储输出

训练时，查询延迟NeRF的MLP，测试时，预计算

接下来，沿光线alpha合成

光线终止后，使用另一个MLP预测视图相关镜面反射颜色，从累积的特征向量、漫反射颜色和光线观察方向，此MLP每个像素仅运行一次



![image-20230830085430781](https://cdn.jsdelivr.net/gh/twtsuif/picture/twtsuif2023-08-30/e26c44d9c4dd61ef344e9c94fa0415b8--a2fc--image-20230830085430781.png)

NeRF与SNeRG的ray marching比较

通过查找预计算的稀疏3D网格

使用间接网格将占用的体素块映射到紧凑的 3D 纹理图集中的位置

ray marching跳过未占用的块，并对沿着光线获取的漫反射颜色和特征向量进行 alpha 合成

一旦累积的不透明度饱和，我们就终止光线行进，并将累积的颜色和特征传递给一个小型 MLP，该 MLP 评估光线的视图相关分量



## 摘要

新的训练NeRF的方法，预计算并存储，即baking，作为新的表示，称为稀疏神经辐射网格SNeRG，商用硬件上实时渲染

- 重新制定NeRF架构
- 具有学习的特征向量的稀疏体素网格表示

每个场景平均小于90M，高于30帧



## 简介

NeRF渲染一帧800*800需要1分钟

比之前加速NeRF渲染的工作快2个数量级，比第二快的替代方案快1个数量级

单个GPU上每帧渲染12ms

**预计算和存储一个训练的NeRF到稀疏3D体素网格**

每个体素包含不透明度、漫反射颜色、编码视图相关效果的学习的特征向量

渲染：沿每条光线累积漫反射颜色和特征向量，累积的特征向量传入通过轻量MLP，生成视图相关的残差，累积添加到漫反射颜色

两个关键的修改

- 设计延迟NeRF，每个像素仅运行一次的MLP，而非像原始NeRF每个3D样本运行一次
- 训练期间，规范NeRF预测的不透明度场，来推动稀疏性



## 相关工作

### 视图合成的场景表示

基于mesh的方法自然适合使用高度优化的光栅化管道进行实时渲染，但训练渲染损失十分困难



另一类方法：离散体积表示(体素网格)、MPI

虽然体积的方法适合梯度优化，但离散体素表示根本上受到立方体缩放的限制

在体素网格下以低分辨率表示场景，在MPI下从有限的视点范围进行渲染，受到限制



NeRF后续工作扩展到生成建模、动态场景、非刚性变形对象、重新照明

NeRF大概5M的模型权重

最近的加速渲染

- AutoInt：设计网络架构，自动计算沿光线积分，逐段ray-marching，需要更少的MLP评估
- NSVF：存储潜码的3D体素网格，训练期间稀疏化该网格，渲染期间跳过可用空间
- DeRF：一组小的MLP

这些方法只能实现10倍

我们关注训练后的渲染，利用训练期间难以合并的预计算策略



#### 高效体渲染

早期体渲染都是关于体素网格的

稀疏体素网格可以是不透明表面的高效表示

在大空间区域共享相同的数据值，或需要预过滤表示来对抗混叠的情况下，分层表示，如稀疏体素八叉树，是表示这种稀疏体积内容的流行数据结构

然而，对于具有详细几何和外观场景，和渲染期间不需要可变细节级的场景，八叉树中间非叶子节点以及查询需要的树遍历，消耗大量内存和时间开销

或者稀疏体素网格可以用Hash表有效表示，渲染期间遍历表示时，独立地散列每个体素可能导致内存获取不连贯



我们使用块稀疏表示来tradeoff，提高内存一致性，稍微增加了大小

将延迟渲染扩展到体积表示



## 方法概述

三个要求

- 商用硬件渲染800*800应该不需要30ms
- 表示形式可压缩至100MB或更小
- 未压缩的表示应该适合显存，大概4GB，且无需流式传输



NeRF大约需要100teraflops渲染单个800*800帧

用存储换计算，然而并不希望预计算并存储整个表示

混合方法：预计算一些内容存储在稀疏3D数据结构中，将依赖于视图的效果推迟到渲染时间

NeRF的重新表述 以及烘培到适合实时渲染的离散体积表示程序



## 为了实时渲染而修改NeRF

三种方式

- 限制视图相关的计算为每条射线的单个网络评估
- 网络架构中引入小瓶颈，可有效存储8位整数
- 训练引入稀疏性损失，不透明场集中在场景中表面周围



### 回顾NeRF

关键决策：体积密度只需要3D坐标进行预测，发射的辐射率由3D坐标和2D方向预测

NeRF的MLP比密集体素网格少多个数量级的空间

然而，训练NeRF后，我们重新考虑这种trade off，将NeRF烘培到存储MLP预计算值的数据结构



### 延迟NeRF架构

NeRF的MLP可以被认为每个输入3D位置预测256维特征向量，将其与观看方向连接并解码为RGB

我们改了他的输出![image-20230829223809273](https://cdn.jsdelivr.net/gh/twtsuif/picture/twtsuif2023-08-29/f42f0dc3aff6d23c4ee28bf5ebfe1df6--745e--image-20230829223809273.png)

4维特征向量vs被sigmoid，以便后续压缩

产生**我们添加到累积的漫反射颜色**的**视图相关残差**

![image-20230829224157860](https://cdn.jsdelivr.net/gh/twtsuif/picture/twtsuif2023-08-29/96e42753963942af9807871ae6ac06c1--f616--image-20230829224157860.png)

我们只需要评估$MLP_\phi$即可为每个像素产生一次视图相关效果，而非3D空间中每个采样点



### 不透明度正则化

体积表示的渲染时间和所需存储在很大程度上取决于场景内不透明度的稀疏性

为了推动NeRF不透明场变得稀疏，添加了正则化器，训练时使用柯西损失来惩罚预测的密度

![image-20230829224731995](https://cdn.jsdelivr.net/gh/twtsuif/picture/twtsuif2023-08-29/3e7db517d49d3c5e9d248ea7cad6c119--673f--image-20230829224731995.png)

i对输入图像的像素索引

k沿射线的样本索引

超参数λs和c控制正则化器的幅度和比例

为了确保这种损失不会由于 NeRF 的分层采样而被不均匀地应用，我们仅针对沿每条射线以均匀密度分布的粗样本计算



## 稀疏神经辐射网格

密集的体素网格可以轻松填满高端GPU，通过利用稀疏性并只存储被占用和可见的体素，最终得到了更紧凑的表示



### 数据结构

使用两个较小的密集数组，以块稀疏格式表示$N^3$体素网格



第一个数组是3D纹理图集，包含多个大小为$B^3$的密集宏块，对应稀疏体积中实际存在的内容(漫反射颜色、特征向量、不透明度)

​	3D图集的每个体素代表密集$N^3$ 网格的全分辨率场景，但3D纹理图集要小很多

​	与基于hash的数据结构，其中$B^3=1$，该方法有利于将空间中接近的内容保存在内存中

第二个数组是低分辨率$(N/B)^3$间接网格，它存储指示完整体素网格内相应 B3 宏块为空的值，或者存储指向该宏块的高分辨率内容的索引在 3D 纹理图集中。

​	可在渲染时跳过空白块



### 渲染

实时渲染

- 预先计算每个3D位置漫反射颜色和特征向量，在数据结构中查找
- 在每个像素，仅评估一个MLP来产生视图相关effect

对于被占用的宏块，以体素宽度1/N步通过3D纹理图集中的相应块，三线性插值获取每个样本位置的值



### 烘培

只为场景中，至少在一个训练视图中非空且可见的体素分配存储



### 压缩

将烘焙的 SNeRG 表示中的所有值量化为 8 位，并分别压缩间接网格和 3D 纹理图集



### 微调

